program: /home/shu4/ECE491B_HW1/ece496b_basics/train.py
method: grid
parameters:
  lr:
    values: 5e-4
  total_iters:
    value: 10000
  batch_size:
    value: 128
  context_length:
    value: 128
  d_model:
    value: 512
  num_layers:
    value: 6
  num_heads:
    value: 8
  d_ff:
    value: 2048
  attn_pdrop:
    value: 0.1
  residual_pdrop:
    value: 0.1
  lr_min:
    value: 1e-5
  warmup_iters:
    value: 1000
  weight_decay:
    value: 0.001
  beta1:
    value: 0.9
  beta2:
    value: 0.999
  eps:
    value: 1e-8
  max_norm:
    value: 1.0
  log_interval:
    value: 100
  checkpoint_interval:
    value: 500
  train_file:
    value: "/home/shu4/ECE491B_HW1/data/Experiment_output/tinystories_train_tokens.npy"
  val_file:
    value: "/home/shu4/ECE491B_HW1/data/Experiment_output/tinystories_valid_tokens.npy"
  checkpoint_dir:
    value: "/home/shu4/ECE491B_HW1/data/Experiment_output/tinystories_checkpoints"
  wandb_project:
    value: "transformer-lm"
