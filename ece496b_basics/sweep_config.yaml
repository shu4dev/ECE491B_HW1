program: /home/shu4/ECE491B_HW1/ece496b_basics/train.py
method: grid
parameters:
  batch_size:
    values: [8, 16, 32, 64]
  total_iters:
    value: 5000
  context_length:
    value: 256
  d_model:
    value: 512
  num_layers:
    value: 4
  num_heads:
    value: 16
  d_ff:
    value: 2048
  attn_pdrop:
    value: 0.1
  residual_pdrop:
    value: 0.1
  lr:
    value: 1e-3
  lr_min:
    value: 1e-5
  warmup_iters:
    value: 1000
  weight_decay:
    value: 0.001
  beta1:
    value: 0.9
  beta2:
    value: 0.999
  eps:
    value: 1e-8
  max_norm:
    value: 1.0
  log_interval:
    value: 100
  checkpoint_interval:
    value: 500
  train_file:
    value: "data/Experiment_output/tinystories_train_tokens.npy"
  val_file:
    value: "data/Experiment_output/tinystories_valid_tokens.npy"
  checkpoint_dir:
    value: "data/Experiment_output/checkpoints"
  wandb_project:
    value: "transformer-lm"
