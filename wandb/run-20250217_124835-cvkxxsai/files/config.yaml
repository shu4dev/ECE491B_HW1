_wandb:
    value:
        cli_version: 0.19.6
        m: []
        python_version: 3.10.16
        t:
            "1":
                - 1
                - 55
            "2":
                - 1
                - 55
            "3":
                - 16
                - 23
                - 55
            "4": 3.10.16
            "5": 0.19.6
            "8":
                - 2
                - 5
            "12": 0.19.6
            "13": linux-x86_64
attn_pdrop:
    value: 0.1
batch_size:
    value: 128
beta1:
    value: 0.9
beta2:
    value: 0.999
checkpoint_dir:
    value: /home/shu4/ECE491B_HW1/data/Experiment_output/tinystories_checkpoints
checkpoint_interval:
    value: 500
context_length:
    value: 256
d_ff:
    value: 2048
d_model:
    value: 512
eps:
    value: 1e-08
log_interval:
    value: 100
lr:
    value: 0.0005
lr_min:
    value: 1e-05
max_norm:
    value: 1
no_cuda:
    value: false
num_heads:
    value: 16
num_layers:
    value: 4
residual_pdrop:
    value: 0.1
total_iters:
    value: 10000
train_file:
    value: /home/shu4/ECE491B_HW1/data/Experiment_output/tinystories_train_tokens.npy
val_file:
    value: /home/shu4/ECE491B_HW1/data/Experiment_output/tinystories_valid_tokens.npy
vocab_size:
    value: 50257
wandb_project:
    value: transformer-lm
warmup_iters:
    value: 1000
weight_decay:
    value: 0.001
